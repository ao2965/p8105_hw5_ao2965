p8105_hw5_ao2965
================
Alissa Shams Orchi
2025-11-14

# Problem 2

### Running the simulations

``` r
n = 30
sigma = 5
alpha = 0.05
n_sim = 5000

sim_t_test = function(mu, n = 30, sigma = 5) {
  sim_data = rnorm(n, mean = mu, sd = sigma)
  test = t.test(sim_data, mu = 0)
  broom::tidy(test) |> 
    select(estimate, p.value)
}

sim_mu_0 = map_dfr(1:n_sim, ~ sim_t_test(mu = 0)) |> 
  mutate(mu_true = 0)

sim_mu_1 = map_dfr(1:n_sim, ~ sim_t_test(mu = 1)) |> 
  mutate(mu_true = 1)

sim_mu_2 = map_dfr(1:n_sim, ~ sim_t_test(mu = 2)) |> 
  mutate(mu_true = 2)

sim_mu_3 = map_dfr(1:n_sim, ~ sim_t_test(mu = 3)) |> 
  mutate(mu_true = 3)

sim_mu_4 = map_dfr(1:n_sim, ~ sim_t_test(mu = 4)) |> 
  mutate(mu_true = 4)

sim_mu_5 = map_dfr(1:n_sim, ~ sim_t_test(mu = 5)) |> 
  mutate(mu_true = 5)

sim_mu_6 = map_dfr(1:n_sim, ~ sim_t_test(mu = 6)) |> 
  mutate(mu_true = 6)

sim_results = bind_rows(
  sim_mu_0,
  sim_mu_1,
  sim_mu_2,
  sim_mu_3,
  sim_mu_4,
  sim_mu_5,
  sim_mu_6
)
```

### Generating the power summary and plot

``` r
power_summary = sim_results |> 
  group_by(mu_true) |> 
  summarize(
    power = mean(p.value < 0.05),
    avg_estimate_all = mean(estimate),
    avg_estimate_rejected = mean(estimate[p.value < 0.05]),
    n_simulations = n()
  )

power_summary
```

    ## # A tibble: 7 × 5
    ##   mu_true power avg_estimate_all avg_estimate_rejected n_simulations
    ##     <dbl> <dbl>            <dbl>                 <dbl>         <int>
    ## 1       0 0.051          -0.0276                -0.392          5000
    ## 2       1 0.191           1.00                   2.25           5000
    ## 3       2 0.551           1.99                   2.63           5000
    ## 4       3 0.892           3.02                   3.20           5000
    ## 5       4 0.986           3.97                   4.01           5000
    ## 6       5 1.000           5.01                   5.01           5000
    ## 7       6 1               5.99                   5.99           5000

``` r
power_plot = power_summary |> 
  ggplot(aes(x = mu_true, y = power)) +
  geom_point(size = 3) +
  geom_line() +
  scale_y_continuous(limits = c(0, 1)) +
  labs(
    title = "Power vs Effect Size",
    x = "True value of μ",
    y = "Power (Proportion of times null was rejected)"
  ) +
  theme_minimal()

power_plot
```

![](p8105_hw5_ao2965_files/figure-gfm/unnamed-chunk-2-1.png)<!-- -->

- As effect size increases, power increases in the plot. This indicates
  a positive association between them. There is a steep increase in
  power when the true value of μ increases from 1 to 4. After reaching
  4, the association plateaus

### Second plot

``` r
estimates_plot = power_summary |> 
  select(mu_true, avg_estimate_all, avg_estimate_rejected) |> 
  pivot_longer(
    cols = starts_with("avg"),
    names_to = "sample_type",
    values_to = "average_estimate"
  ) |> 
  mutate(
    sample_type = case_when(
      sample_type == "avg_estimate_all" ~ "All samples",
      sample_type == "avg_estimate_rejected" ~ "Rejected null only"
    )
  ) |> 
  ggplot(aes(x = mu_true, y = average_estimate)) +
  geom_point(size = 3, color = "blue") +
  geom_line(color = "blue") +
  facet_wrap(~ sample_type, ncol = 2) +  
  labs(
    title = "Average Estimate of μ̂ by True μ",
    x = "True value of μ",
    y = "Average estimate of μ̂"
  ) +
  geom_abline(slope = 1, intercept = 0,   
            linetype = "dashed", alpha = 0.5) +
  theme_minimal()

estimates_plot
```

![](p8105_hw5_ao2965_files/figure-gfm/estimates-plot-faceted-1.png)<!-- -->

- The sample average of μ̂ across tests where the null was rejected is
  not approximately equal to the true μ, especially for small effect
  sizes. This occurs because when the true effect is small, we only
  reject the null when random variation produces unusually large
  estimates. This selection bias disappears as power increases because
  nearly all samples lead to rejection.

# Problem 3

### Raw data

``` r
homicide_data = read_csv("homicide-data.csv")

n_obs = nrow(homicide_data)
n_vars = ncol(homicide_data)
var_names = names(homicide_data) |> str_c(collapse = ", ")
```

- The Washington Post homicide dataset contains 52,179 observations and
  12 variables. The variables included are: uid, reported_date,
  victim_last, victim_first, victim_race, victim_age, victim_sex, city,
  state, lat, lon, disposition.

### Create city_state variable and summarize

``` r
homicide_summary = homicide_data |> 
  mutate(
    city_state = str_c(city, ", ", state),
    city_state = str_replace(city_state, "Milwaukee, wI", "Milwaukee, WI"),
    resolution = case_when(
      disposition == "Closed without arrest" ~ "unsolved",
      disposition == "Open/No arrest" ~ "unsolved", 
      disposition == "Closed by arrest" ~ "solved"
    )
  ) |> 
  filter(city_state != "Tulsa, AL") |> 
  group_by(city_state) |> 
  summarize(
    total_homicides = n(),
    unsolved_homicides = sum(resolution == "unsolved"),
    .groups = "drop"
  )

homicide_summary |> 
  arrange(desc(total_homicides))
```

    ## # A tibble: 50 × 3
    ##    city_state       total_homicides unsolved_homicides
    ##    <chr>                      <int>              <int>
    ##  1 Chicago, IL                 5535               4073
    ##  2 Philadelphia, PA            3037               1360
    ##  3 Houston, TX                 2942               1493
    ##  4 Baltimore, MD               2827               1825
    ##  5 Detroit, MI                 2519               1482
    ##  6 Los Angeles, CA             2257               1106
    ##  7 St. Louis, MO               1677                905
    ##  8 Dallas, TX                  1567                754
    ##  9 Memphis, TN                 1514                483
    ## 10 New Orleans, LA             1434                930
    ## # ℹ 40 more rows

``` r
homicide_summary |> 
  arrange(desc(unsolved_homicides))
```

    ## # A tibble: 50 × 3
    ##    city_state       total_homicides unsolved_homicides
    ##    <chr>                      <int>              <int>
    ##  1 Chicago, IL                 5535               4073
    ##  2 Baltimore, MD               2827               1825
    ##  3 Houston, TX                 2942               1493
    ##  4 Detroit, MI                 2519               1482
    ##  5 Philadelphia, PA            3037               1360
    ##  6 Los Angeles, CA             2257               1106
    ##  7 New Orleans, LA             1434                930
    ##  8 St. Louis, MO               1677                905
    ##  9 Dallas, TX                  1567                754
    ## 10 Jacksonville, FL            1168                597
    ## # ℹ 40 more rows

- After summarizing the total number of homicides, we see that the 5
  cities with the highest number of total homicides are Chicago,
  Philadelphia, Houston, Baltimore, Detroit.

- After summarizing the total number of unsolved_homicides, we see that
  the 5 cities with the highest number of total unsolved_homicides are
  Chicago, Baltimore, Houston, Detroit, Philadelphia.

### Baltimore prop.test

``` r
run_prop_test = function(unsolved, total) {
  test = prop.test(x = unsolved, n = total)
  broom::tidy(test) |> 
    select(estimate, conf.low, conf.high)
}
baltimore_data = homicide_summary |> 
  filter(city_state == "Baltimore, MD")

baltimore_results = run_prop_test(
  unsolved = baltimore_data |> pull(unsolved_homicides),
  total = baltimore_data |> pull(total_homicides)
)
baltimore_results
```

    ## # A tibble: 1 × 3
    ##   estimate conf.low conf.high
    ##      <dbl>    <dbl>     <dbl>
    ## 1    0.646    0.628     0.663

### All cities prop.test

``` r
all_cities = homicide_summary |> 
  mutate(
    test_results = map2(
      unsolved_homicides, 
      total_homicides, 
      run_prop_test
    )
  ) |> 
  unnest(test_results)

all_cities
```

    ## # A tibble: 50 × 6
    ##    city_state     total_homicides unsolved_homicides estimate conf.low conf.high
    ##    <chr>                    <int>              <int>    <dbl>    <dbl>     <dbl>
    ##  1 Albuquerque, …             378                146    0.386    0.337     0.438
    ##  2 Atlanta, GA                973                373    0.383    0.353     0.415
    ##  3 Baltimore, MD             2827               1825    0.646    0.628     0.663
    ##  4 Baton Rouge, …             424                196    0.462    0.414     0.511
    ##  5 Birmingham, AL             800                347    0.434    0.399     0.469
    ##  6 Boston, MA                 614                310    0.505    0.465     0.545
    ##  7 Buffalo, NY                521                319    0.612    0.569     0.654
    ##  8 Charlotte, NC              687                206    0.300    0.266     0.336
    ##  9 Chicago, IL               5535               4073    0.736    0.724     0.747
    ## 10 Cincinnati, OH             694                309    0.445    0.408     0.483
    ## # ℹ 40 more rows

### Create Plot

``` r
homicide_plot = all_cities |> 
  mutate(city_state = fct_reorder(city_state, estimate)) |> 
  ggplot(aes(x = city_state, y = estimate)) +
  geom_point(size = 2, color = "darkblue") +
  geom_errorbar(
    aes(ymin = conf.low, ymax = conf.high),
    width = 0.3,
    alpha = 0.7
  ) +
  coord_flip() +
  scale_y_continuous(limits = c(0, 1), breaks = seq(0, 1, 0.2)) +
  labs(
    title = "Proportion of Unsolved Homicides by City",
    subtitle = "Error bars represent 95% confidence intervals",
    x = "city,state",
    y = "Proportion of Unsolved Homicides"
  ) +
  theme_minimal() +
  theme(
    axis.text.y = element_text(size = 7),
    plot.title = element_text(size = 14, face = "bold"),
    plot.subtitle = element_text(size = 10)
  )

homicide_plot
```

![](p8105_hw5_ao2965_files/figure-gfm/unnamed-chunk-7-1.png)<!-- -->
